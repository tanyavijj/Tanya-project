{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMmkJrFpI5z3jJ1R34OArOc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanyavijj/Tanya-project/blob/main/SRGAN_FINAL_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Define paths\n",
        "zip_path = \"/content/drive/MyDrive/archive (5).zip\"\n",
        "extract_dir = \"/content/dataset\"\n",
        "\n",
        "# Extract dataset\n",
        "if not os.path.exists(extract_dir):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Define HR image folders\n",
        "train_dir = \"/content/drive/MyDrive/archive (5)/DIV2K_train_HR\"\n",
        "val_dir = \"/content/drive/MyDrive/archive (5)/DIV2K_valid_HR\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yShoaFHjGBue",
        "outputId": "4cc36c7a-f2b6-4e18-e7bf-bc35f8ce3a5f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import cv2\n",
        "\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gHElBHnGPoA",
        "outputId": "f8c0b4c1-e9fd-4ffb-adef-988f7155eb05"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import cv2\n",
        "\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# %%\n",
        "def preprocess_image(path):\n",
        "    hr_image = tf.io.read_file(path)\n",
        "    hr_image = tf.image.decode_png(hr_image, channels=3)\n",
        "    hr_image = tf.image.convert_image_dtype(hr_image, tf.float32)\n",
        "    hr_image = tf.image.resize(hr_image, [96, 96])  # HR target\n",
        "\n",
        "    lr_image = tf.image.resize(hr_image, [24, 24])  # Downscale to LR\n",
        "    return lr_image, hr_image\n",
        "\n",
        "\n",
        "def load_dataset(folder, max_images=100):\n",
        "    images = os.listdir(folder)[:max_images]\n",
        "    data = []\n",
        "    for img in images:\n",
        "        # Check if the current item is a file before processing\n",
        "        image_path = os.path.join(folder, img)\n",
        "        if os.path.isfile(image_path):\n",
        "            data.append(preprocess_image(image_path))\n",
        "\n",
        "    # Check if data is empty before unpacking\n",
        "    if not data:\n",
        "        print(f\"Warning: No image files found in {folder}. Returning empty dataset.\")\n",
        "        return tf.data.Dataset.from_tensor_slices((np.array([]), np.array([]))).batch(4)\n",
        "\n",
        "    lrs, hrs = zip(*data)\n",
        "    return tf.data.Dataset.from_tensor_slices((np.array(lrs), np.array(hrs))).batch(4)\n",
        "\n",
        "train_dataset = load_dataset(train_dir)\n",
        "val_dataset = load_dataset(val_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as4FhWnmGPkY",
        "outputId": "1b2bc07a-ed51-430d-a3ab-24fdc819da16"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available: 1\n",
            "Warning: No image files found in /content/drive/MyDrive/archive (5)/DIV2K_train_HR. Returning empty dataset.\n",
            "Warning: No image files found in /content/drive/MyDrive/archive (5)/DIV2K_valid_HR. Returning empty dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "    def res_block(x_in):\n",
        "        x = layers.Conv2D(64, 3, padding='same')(x_in)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation('relu')(x)  # Use Keras Activation layer\n",
        "        x = layers.Conv2D(64, 3, padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        return layers.Add()([x_in, x])\n",
        "\n",
        "    inputs = layers.Input(shape=(96, 96, 3))\n",
        "    x = layers.Conv2D(64, 9, padding='same')(inputs)\n",
        "    x = layers.Activation('relu')(x)  # Use Keras Activation layer\n",
        "    skip = x\n",
        "    for _ in range(16):\n",
        "        x = res_block(x)\n",
        "    x = layers.Conv2D(64, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Add()([x, skip])\n",
        "    for _ in range(2):\n",
        "        x = layers.Conv2D(256, 3, padding='same')(x)\n",
        "        # Wrap tf.nn.depth_to_space in a Lambda layer\n",
        "        x = layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2))(x)\n",
        "        x = layers.Activation('relu')(x)  # Use Keras Activation layer\n",
        "    x = layers.Conv2D(3, 9, padding='same', activation='tanh')(x)\n",
        "    return models.Model(inputs, x)\n",
        "\n",
        "def build_discriminator():\n",
        "    def disc_block(x, filters, strides):\n",
        "        x = layers.Conv2D(filters, 3, strides=strides, padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        return x\n",
        "\n",
        "    inputs = layers.Input(shape=(96, 96, 3))\n",
        "    x = layers.Conv2D(64, 3, strides=1, padding='same')(inputs)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "    for filters, strides in [(64, 2), (128, 1), (128, 2), (256, 1), (256, 2), (512, 1), (512, 2)]:\n",
        "        x = disc_block(x, filters, strides)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(1024)(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "    x = layers.Dense(1, activation='sigmoid')(x)\n",
        "    return models.Model(inputs, x)\n",
        "\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n"
      ],
      "metadata": {
        "id": "OspEgE5nGPg9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet', input_shape=(96, 96, 3))\n",
        "vgg.trainable = False\n",
        "vgg_model = tf.keras.Model(inputs=vgg.input, outputs=vgg.get_layer(\"block5_conv4\").output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czfuUXxOGdgR",
        "outputId": "883ec79e-6dc6-4a43-cb0f-48bacf3aafa5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bce_loss = tf.keras.losses.BinaryCrossentropy()\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"
      ],
      "metadata": {
        "id": "N_5ITFSfGdck"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "    for step, (lr, hr) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            sr = generator(lr, training=True)\n",
        "            real_output = discriminator(hr, training=True)\n",
        "            fake_output = discriminator(sr, training=True)\n",
        "\n",
        "            hr_features = vgg_model(hr)\n",
        "            sr_features = vgg_model(sr)\n",
        "            content_loss = tf.reduce_mean(tf.square(hr_features - sr_features))\n",
        "            adv_loss = bce_loss(tf.ones_like(fake_output), fake_output)\n",
        "            gen_loss = content_loss + 1e-3 * adv_loss\n",
        "\n",
        "            real_loss = bce_loss(tf.ones_like(real_output), real_output)\n",
        "            fake_loss = bce_loss(tf.zeros_like(fake_output), fake_output)\n",
        "            disc_loss = real_loss + fake_loss\n",
        "\n",
        "        gen_grads = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        disc_grads = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "        generator_optimizer.apply_gradients(zip(gen_grads, generator.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(disc_grads, discriminator.trainable_variables))\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Step {step} | Gen Loss: {gen_loss:.4f} | Disc Loss: {disc_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yjgiKi1GdZ6",
        "outputId": "4058d81a-4a33-4d2f-f045-d84e87cf33e3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 5/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sr_img, hr_img):\n",
        "    sr = np.clip(sr_img * 255, 0, 255).astype(np.uint8)\n",
        "    hr = np.clip(hr_img * 255, 0, 255).astype(np.uint8)\n",
        "    psnr_val = tf.image.psnr(sr, hr, max_val=255).numpy()\n",
        "    ssim_val = ssim(hr, sr, multichannel=True)\n",
        "    return psnr_val, ssim_val\n",
        "\n",
        "for lr, hr in val_dataset.take(1):\n",
        "    sr = generator(lr, training=False)\n",
        "    for i in range(len(sr)):\n",
        "        psnr_val, ssim_val = evaluate(sr[i].numpy(), hr[i].numpy())\n",
        "        print(f\"Image {i+1}: PSNR = {psnr_val:.2f}, SSIM = {ssim_val:.4f}\")\n"
      ],
      "metadata": {
        "id": "g6XtiktCGdXN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wtYdcToWGdUY"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}